{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": " Neural Network in  Tensorflow on MNIST.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/himanshuRepo/CoLab_Notebooks/blob/master/Neural_Network_in_Tensorflow_on_MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "4JQBCcaFSLq-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Neural Network on MNIST Dataset"
      ]
    },
    {
      "metadata": {
        "id": "R9SRvU8_Nbxz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Mount the Google Drive"
      ]
    },
    {
      "metadata": {
        "id": "gypVf8rdNfED",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WQLF6EGRb0Ay",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Check the working directory"
      ]
    },
    {
      "metadata": {
        "id": "rKSQOqJ0SnaY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!ls \"/content/drive/My Drive/\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3zqXiiK6cDHB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Change to a specific folder on Google Drive"
      ]
    },
    {
      "metadata": {
        "id": "eFlxNymBS1s1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir(\"drive/My Drive/\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TNm_HcK9Nmpp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Displaying the considered neural network"
      ]
    },
    {
      "metadata": {
        "id": "b8Z1xoJQSLq_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from IPython.display import Image\n",
        "Image('./images/Page34.jpg')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3356Fq-xSLrE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "* Creating a simple three layer neural network by using the\n",
        "  MNIST dataset that the TensorFlow package provides\n",
        "\n",
        "* This MNIST dataset is a set of 28 X 28 pixel grayscale images\n",
        "  which represent hand-written digits\n",
        "\n",
        "* It has 55,000 training rows, 10,000 testing rows and 5,000\n",
        "  validation rows"
      ]
    },
    {
      "metadata": {
        "id": "OP3Zs-dqN1K7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Importing the libraries"
      ]
    },
    {
      "metadata": {
        "id": "0Cl5iOdqSLrF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KGxGW6H5T_-I",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from tensorboardcolab import TensorBoardColab, TensorBoardColabCallback\n",
        "tbc=TensorBoardColab()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qvfXeJ6HSLrH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Load Dataset"
      ]
    },
    {
      "metadata": {
        "id": "Fc3IKNi9SLrI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "F7Pu4ng5SLrL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Get the first images from the test-set.\n",
        "images = mnist.test.images[0:9]\n",
        "plt.imshow(images[0].reshape(28,28), cmap='binary')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tdsoVAm_SLrO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Variable Set up"
      ]
    },
    {
      "metadata": {
        "id": "igd1AtKSSLrP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Python optimisation variables\n",
        "learning_rate = 0.5\n",
        "epochs = 10\n",
        "batch_size = 100\n",
        "\n",
        "# declare the training data placeholders\n",
        "# input x - for 28 x 28 pixels = 784\n",
        "x = tf.placeholder(tf.float32, [None, 784])\n",
        "# now declare the output data placeholder - 10 digits\n",
        "y = tf.placeholder(tf.float32, [None, 10])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HPCDV61ySLrR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Weight and Bias Code"
      ]
    },
    {
      "metadata": {
        "id": "zAE5Bu3VSLrS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# now declare the weights connecting the input to the hidden layer\n",
        "W1 = tf.Variable(tf.random_normal([784, 300], stddev=0.03), name='W1')\n",
        "b1 = tf.Variable(tf.random_normal([300]), name='b1')\n",
        "# and the weights connecting the hidden layer to the output layer\n",
        "W2 = tf.Variable(tf.random_normal([300, 10], stddev=0.03), name='W2')\n",
        "b2 = tf.Variable(tf.random_normal([10]), name='b2')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "15Ntal5cSLrU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Hidden Layer Node Setup"
      ]
    },
    {
      "metadata": {
        "id": "_zZkBUrnSLrV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# calculate the output of the hidden layer\n",
        "hidden_out = tf.add(tf.matmul(x, W1), b1)\n",
        "hidden_out = tf.nn.relu(hidden_out)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rLXh7rUSSLrY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Output Layer Node Setup"
      ]
    },
    {
      "metadata": {
        "id": "FB38nq8mSLrZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Setup the output layer, y_"
      ]
    },
    {
      "metadata": {
        "id": "UitVhZh7SLra",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# now calculate the hidden layer output - in this case, let's use a softmax activated\n",
        "# output layer\n",
        "y_ = tf.nn.softmax(tf.add(tf.matmul(hidden_out, W2), b2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0yq3mJRDSLrc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Optimisation function"
      ]
    },
    {
      "metadata": {
        "id": "PrOVRkcbSLrd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Cross entropy cost function"
      ]
    },
    {
      "metadata": {
        "id": "BhY9G2BbSLre",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from IPython.display import Image\n",
        "Image('./images/crossentropy.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EWfx5oXqSLrh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y_clipped = tf.clip_by_value(y_, 1e-10, 0.9999999)\n",
        "cross_entropy = -tf.reduce_mean(tf.reduce_sum(y * tf.log(y_clipped)+ (1 - y) * tf.log(1 - y_clipped), axis=1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EQOEu9XJSLrj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Optimizer Algorithm Setup"
      ]
    },
    {
      "metadata": {
        "id": "X6JeUWYmSLrj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This function will then perform the gradient descent and the\n",
        "backpropagation for you."
      ]
    },
    {
      "metadata": {
        "id": "UT-jahbnSLrk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# add an optimiser\n",
        "optimiser = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(cross_entropy)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bhhBuZJHSLro",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Accuracy Code"
      ]
    },
    {
      "metadata": {
        "id": "Zbla9wxlSLrp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Setup the variable initialisation operation and an operation to\n",
        "measure the accuracy of our predictions"
      ]
    },
    {
      "metadata": {
        "id": "kpQUiocoSLrq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# finally setup the initialisation operator\n",
        "init_op = tf.global_variables_initializer()\n",
        "\n",
        "# define an accuracy assessment operation\n",
        "correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cTH46__6SLrt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Setup Code for the Training Process"
      ]
    },
    {
      "metadata": {
        "id": "HTWS75RNSLru",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# start the session\n",
        "with tf.Session() as sess:\n",
        "  # initialise the variables\n",
        "  sess.run(init_op)\n",
        "  total_batch = int(len(mnist.train.labels) / batch_size)\n",
        "  for epoch in range(epochs):\n",
        "    avg_cost = 0\n",
        "    for i in range(total_batch):\n",
        "      batch_x, batch_y = mnist.train.next_batch(batch_size=batch_size)\n",
        "      _, c = sess.run([optimiser, cross_entropy], feed_dict={x: batch_x, y: batch_y})\n",
        "      avg_cost += c / total_batch\n",
        "      print(\"Epoch:\", (epoch + 1), \"cost =\", \"{:.3f}\".format(avg_cost))\n",
        "  print(sess.run(accuracy, feed_dict={x: mnist.test.images, y: mnist.test.labels}))\n",
        "  summary_writer = tbc.get_writer()\n",
        "  summary_writer.add_graph(sess.graph)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}